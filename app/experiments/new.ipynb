{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\")\n",
    "audio_file = open(\"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/ahista_ahista/audio_files/ahista_ahista_part1_audio.mp3\", \"rb\")\n",
    "\n",
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file, \n",
    "  response_format=\"verbose_json\",\n",
    "  prompt = (\n",
    "    \"This is a professionally recorded Hindi movie. \"\n",
    "    \"The audio includes male, female, and child speakers. \"\n",
    "    \"Language is Hindi, often poetic and emotional. \"\n",
    "    \"There may be ambient sounds or music. \"\n",
    "    \"Transcribe spoken content accurately including honorifics and slang. \"\n",
    "    \"Include both Hindi and English words as spoken. \"\n",
    "    \"Character names include Ravi, Pooja, Inspector Khan, and Sita.\"\n",
    ")\n",
    ")\n",
    "\n",
    "print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0b320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def to_srt_time(seconds):\n",
    "    td = datetime.timedelta(seconds=seconds)\n",
    "    total_seconds = int(td.total_seconds())\n",
    "    milliseconds = int((td.total_seconds() - total_seconds) * 1000)\n",
    "    return str(td).split('.')[0].zfill(8).replace(\".\", \",\") + f\",{milliseconds:03}\"\n",
    "\n",
    "def save_srt_from_transcription(transcription, srt_output_path, min_duration=1.0):\n",
    "    segments = transcription.segments\n",
    "    merged_segments = []\n",
    "    \n",
    "    prev_text = None\n",
    "    current_start = None\n",
    "    current_end = None\n",
    "\n",
    "    for segment in segments:\n",
    "        text = segment.text.strip()\n",
    "        start = segment.start\n",
    "        end = segment.end\n",
    "\n",
    "        if prev_text == text and (start - current_end) <= 1.0:\n",
    "            # Extend the previous segment\n",
    "            current_end = end\n",
    "            merged_segments[-1]['end'] = end\n",
    "        else:\n",
    "            # Start a new segment\n",
    "            merged_segments.append({'start': start, 'end': end, 'text': text})\n",
    "            current_start = start\n",
    "            current_end = end\n",
    "            prev_text = text\n",
    "\n",
    "    # Write merged to SRT\n",
    "    with open(srt_output_path, 'w', encoding='utf-8') as srt_file:\n",
    "        for idx, seg in enumerate(merged_segments, start=1):\n",
    "            duration = seg['end'] - seg['start']\n",
    "            if duration < min_duration:\n",
    "                continue  # optionally skip very short segments\n",
    "            start = to_srt_time(seg['start'])\n",
    "            end = to_srt_time(seg['end'])\n",
    "            srt_file.write(f\"{idx}\\n{start} --> {end}\\n{seg['text']}\\n\\n\")\n",
    "\n",
    "\n",
    "# Save the SRT\n",
    "save_srt_from_transcription(transcription, \"ahista_ahista_part11.srt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7958d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import datetime\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# 1. Preprocess the audio to clean artifacts\n",
    "def preprocess_audio(input_path, output_path=\"cleaned.wav\"):\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",  # Overwrite if exists\n",
    "        \"-i\", input_path,\n",
    "        \"-ar\", \"16000\",  # 16kHz sample rate\n",
    "        \"-ac\", \"1\",      # mono\n",
    "        \"-af\", \"dynaudnorm\",  # dynamic audio normalization\n",
    "        output_path\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"‚úÖ Audio preprocessed and saved to: {output_path}\")\n",
    "        return output_path\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise RuntimeError(f\"‚ùå FFmpeg failed: {e}\")\n",
    "\n",
    "\n",
    "# 2. Format timestamp for SRT\n",
    "def to_srt_time(seconds):\n",
    "    td = datetime.timedelta(seconds=seconds)\n",
    "    total_seconds = int(td.total_seconds())\n",
    "    milliseconds = int((td.total_seconds() - total_seconds) * 1000)\n",
    "    return str(td).split('.')[0].zfill(8).replace(\".\", \",\") + f\",{milliseconds:03}\"\n",
    "\n",
    "\n",
    "# 3. Filter repetitive segments\n",
    "def filter_repeated_segments(segments, min_gap=1.0, max_repeats=2):\n",
    "        \"\"\"\n",
    "        Filters out segments that repeat too often in close succession.\n",
    "\n",
    "        Args:\n",
    "            segments (list): List of segments with `.text`, `.start`, and `.end`.\n",
    "            min_gap (float): Minimum time gap to allow same text again.\n",
    "            max_repeats (int): Max allowed repetitions of the same text.\n",
    "\n",
    "        Returns:\n",
    "            list: Filtered list of segments.\n",
    "        \"\"\"\n",
    "        filtered = []\n",
    "        prev_text = \"\"\n",
    "        prev_end = 0\n",
    "        repeat_count = 0\n",
    "\n",
    "        for seg in segments:\n",
    "            current_text = seg.text.strip()\n",
    "            if current_text == prev_text.strip() and (seg.start - prev_end) < min_gap:\n",
    "                repeat_count += 1\n",
    "                if repeat_count >= max_repeats:\n",
    "                    continue  # Skip this repeated segment\n",
    "            else:\n",
    "                repeat_count = 0  # Reset for a new phrase\n",
    "\n",
    "            filtered.append(seg)\n",
    "            prev_text = current_text\n",
    "            prev_end = seg.end\n",
    "\n",
    "        return filtered\n",
    "\n",
    "\n",
    "# 4. Merge short identical subtitles and write SRT\n",
    "def save_srt_from_transcription(segments, srt_output_path, min_duration=1.0):\n",
    "    merged = []\n",
    "    prev_text = None\n",
    "    current_start = None\n",
    "    current_end = None\n",
    "\n",
    "    for seg in segments:\n",
    "        text = seg.text.strip()\n",
    "        start = seg.start\n",
    "        end = seg.end\n",
    "\n",
    "        if prev_text == text and (start - current_end) <= 1.0:\n",
    "            merged[-1]['end'] = end\n",
    "        else:\n",
    "            merged.append({'start': start, 'end': end, 'text': text})\n",
    "            current_start = start\n",
    "            current_end = end\n",
    "            prev_text = text\n",
    "\n",
    "    # Write to SRT\n",
    "    with open(srt_output_path, 'w', encoding='utf-8') as f:\n",
    "        for idx, seg in enumerate(merged, start=1):\n",
    "            if seg['end'] - seg['start'] < min_duration:\n",
    "                continue\n",
    "            start = to_srt_time(seg['start'])\n",
    "            end = to_srt_time(seg['end'])\n",
    "            f.write(f\"{idx}\\n{start} --> {end}\\n{seg['text']}\\n\\n\")\n",
    "\n",
    "    print(f\"‚úÖ SRT saved to: {srt_output_path}\")\n",
    "\n",
    "\n",
    "# 5. Complete pipeline runner\n",
    "def run_translation_pipeline(\n",
    "    input_audio_path,\n",
    "    api_key,\n",
    "    srt_output_path=\"output_translated.srt\"\n",
    "):\n",
    "    # Step 1: Preprocess\n",
    "    cleaned_audio = preprocess_audio(input_audio_path)\n",
    "\n",
    "    # Step 2: Translate using OpenAI Whisper API\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    with open(cleaned_audio, \"rb\") as audio_file:\n",
    "        result = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file,\n",
    "            response_format=\"verbose_json\",\n",
    "            language=\"hi\",  # original audio language\n",
    "            translate=True,  # translate to English\n",
    "            prompt=(\n",
    "                \"This is a professionally recorded Hindi movie. \"\n",
    "                \"Translate all spoken Hindi to fluent, grammatically correct English. \"\n",
    "                \"Preserve tone, intent, and avoid hallucinating or repeating any content.\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Step 3: Clean segments\n",
    "    segments = filter_repeated_segments(result.segments)\n",
    "\n",
    "    # Step 4: Save as SRT\n",
    "    save_srt_from_transcription(segments, srt_output_path)\n",
    "\n",
    "\n",
    "# # ----------------------\n",
    "# # ‚úÖ Usage Example\n",
    "# # ----------------------\n",
    "# if __name__ == \"__main__\":\n",
    "#     run_translation_pipeline(\n",
    "#         input_audio_path=\"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/ahista_ahista/audio_files/ahista_ahista_part1_audio.mp3\",\n",
    "#         api_key=\"sk-proj-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n",
    "#         srt_output_path=\"ahista_ahista_part1_translated.srt\"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5479f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_translation_pipeline(\n",
    "        input_audio_path=\"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/ahista_ahista/audio_files/ahista_ahista_part1_audio.mp3\",\n",
    "        api_key=\"\",\n",
    "        srt_output_path=\"ahista_ahista_part1_translated12.srt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d8d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "def preprocess_audio(input_path, output_path=\"cleaned.wav\"):\n",
    "    command = [\n",
    "        \"ffmpeg\", \"-y\", \"-i\", input_path,\n",
    "        \"-ar\", \"16000\", \"-ac\", \"1\",\n",
    "        \"-af\", \"dynaudnorm\", output_path\n",
    "    ]\n",
    "    subprocess.run(command, check=True)\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def to_srt_time(seconds):\n",
    "    td = datetime.timedelta(seconds=seconds)\n",
    "    total_seconds = int(td.total_seconds())\n",
    "    milliseconds = int((seconds - total_seconds) * 1000)\n",
    "    time_str = str(td).split('.')[0].zfill(8).replace(\".\", \",\")\n",
    "    return f\"{time_str},{milliseconds:03}\"\n",
    "\n",
    "\n",
    "def get_transcription_segments(audio_path, api_key):\n",
    "    url = \"https://api.openai.com/v1/audio/transcriptions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    with open(audio_path, \"rb\") as f:\n",
    "        files = {\"file\": (audio_path, f, \"audio/wav\")}\n",
    "        data = {\n",
    "            \"model\": \"whisper-1\",\n",
    "            \"response_format\": \"verbose_json\",\n",
    "            \"language\": \"hi\",  # for proper alignment\n",
    "        }\n",
    "        response = requests.post(url, headers=headers, files=files, data=data)\n",
    "        return response.json()[\"segments\"]\n",
    "\n",
    "\n",
    "def get_translated_text(audio_path, api_key):\n",
    "    import sys\n",
    "    url = \"https://api.openai.com/v1/audio/translations\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "    with open(audio_path, \"rb\") as f:\n",
    "        files = {\n",
    "            \"file\": (audio_path, f, \"audio/wav\"),\n",
    "        }\n",
    "        data = {\n",
    "            \"model\": \"whisper-1\",\n",
    "            \"response_format\": \"json\",\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, headers=headers, files=files, data=data)\n",
    "\n",
    "        # Handle non-200 responses or empty responses\n",
    "        if not response.ok:\n",
    "            print(f\"‚ùå HTTP {response.status_code} - {response.reason}\")\n",
    "            print(\"üîç Response content:\")\n",
    "            print(response.text[:1000], file=sys.stderr)  # Print first 1000 characters\n",
    "            response.raise_for_status()\n",
    "\n",
    "        try:\n",
    "            return response.json()[\"text\"]\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå Failed to parse JSON response:\")\n",
    "            print(response.text[:1000], file=sys.stderr)\n",
    "            raise e\n",
    "\n",
    "\n",
    "def split_translated_text(translated_text, segment_count):\n",
    "    # Simple greedy split based on punctuation and segment count\n",
    "    import re\n",
    "    sentences = re.split(r'(?<=[.?!])\\s+', translated_text)\n",
    "    if len(sentences) < segment_count:\n",
    "        # Pad\n",
    "        sentences += [\"\"] * (segment_count - len(sentences))\n",
    "    elif len(sentences) > segment_count:\n",
    "        # Merge excess\n",
    "        merged = []\n",
    "        chunk_size = len(sentences) // segment_count\n",
    "        for i in range(0, len(sentences), chunk_size):\n",
    "            merged.append(\" \".join(sentences[i:i+chunk_size]))\n",
    "        return merged[:segment_count]\n",
    "    return sentences[:segment_count]\n",
    "\n",
    "\n",
    "def save_srt(segments, translated_sentences, srt_path):\n",
    "    with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for idx, (seg, txt) in enumerate(zip(segments, translated_sentences), start=1):\n",
    "            start = to_srt_time(seg[\"start\"])\n",
    "            end = to_srt_time(seg[\"end\"])\n",
    "            f.write(f\"{idx}\\n{start} --> {end}\\n{txt.strip()}\\n\\n\")\n",
    "    print(f\"‚úÖ Saved SRT: {srt_path}\")\n",
    "\n",
    "\n",
    "def run_dual_pass_translation_pipeline(input_audio, api_key, srt_output_path):\n",
    "    cleaned = preprocess_audio(input_audio)\n",
    "    print(\"üîÅ Getting transcription for timestamps...\")\n",
    "    segments = get_transcription_segments(cleaned, api_key)\n",
    "    print(\"üåç Getting translated text...\")\n",
    "    translated_text = get_translated_text(cleaned, api_key)\n",
    "    print(\"‚úÇÔ∏è Splitting translation...\")\n",
    "    translated_lines = split_translated_text(translated_text, len(segments))\n",
    "    print(\"üíæ Saving SRT...\")\n",
    "    save_srt(segments, translated_lines, srt_output_path)\n",
    "\n",
    "\n",
    "# üîß Usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     run_dual_pass_translation_pipeline(\n",
    "#         input_audio=\"/path/to/audio.mp3\",\n",
    "#         api_key=\"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n",
    "#         srt_output_path=\"translated_output.srt\"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb34103",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dual_pass_translation_pipeline(\n",
    "        input_audio=\"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/ahista_ahista/audio_files/ahista_ahista_part1_audio.mp3\",\n",
    "        api_key=\"\",\n",
    "        srt_output_path=\"ahista_ahista_part1_translated12.srt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d13dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/ahista_ahista/split_files/ahista_ahista_part1.mp4\"\n",
    "subtitle_path = \"/home/csc/Documents/Multilingual-Transcriber/plugins/experiments/ahista_ahista_part1_telugu.ass\"\n",
    "output_path = \"/home/csc/Documents/Multilingual-Transcriber/plugins/experiments/ahista_ahista_part1_subtitled_telugu.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6600d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "def ensure_utf8_encoding(input_srt: str, output_srt: str):\n",
    "    \"\"\"Ensure subtitle file is UTF-8 encoded.\"\"\"\n",
    "    with open(input_srt, 'r', encoding='utf-8', errors='replace') as f:\n",
    "        content = f.read()\n",
    "    with open(output_srt, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def burn_subtitles_to_video(video_path: str, subtitle_path: str, output_path: str, font_name: str = \"Noto Sans Telugu\"):\n",
    "    \"\"\"Burn subtitles into a video using FFmpeg with specified font.\"\"\"\n",
    "    # Ensure subtitle file is UTF-8 encoded\n",
    "    utf8_subtitle_path = os.path.splitext(subtitle_path)[0] + \"_utf8.srt\"\n",
    "    ensure_utf8_encoding(subtitle_path, utf8_subtitle_path)\n",
    "\n",
    "    # Escape subtitle path for FFmpeg if it contains spaces\n",
    "    escaped_subs_path = utf8_subtitle_path.replace(\":\", \"\\\\:\").replace(\",\", \"\\\\,\").replace(\" \", \"\\\\ \")\n",
    "\n",
    "    # Construct the FFmpeg command\n",
    "    command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",  # Overwrite output\n",
    "        \"-i\", video_path,\n",
    "        \"-vf\", f\"subtitles='{escaped_subs_path}':force_style='FontName={font_name}'\",\n",
    "        \"-c:a\", \"copy\",\n",
    "        output_path\n",
    "    ]\n",
    "\n",
    "    print(f\"Running FFmpeg command:\\n{' '.join(command)}\")\n",
    "    subprocess.run(command, check=True)\n",
    "    print(f\"‚úÖ Subtitle burned video saved at: {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4018afae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video_path = \"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/ahista_ahista/split_files/ahista_ahista_part1.mp4\"              # Update this path\n",
    "subtitle_path = \"/home/csc/Documents/Multilingual-Transcriber/plugins/experiments/ahista_ahista_part1_telugu.srt\"      # Update this path\n",
    "output_path = \"/home/csc/Documents/Multilingual-Transcriber/plugins/experiments/ahista_ahista_part1_subtitled_telugu_new.mp4\"   # Update this path\n",
    "burn_subtitles_to_video(video_path, subtitle_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b447cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "command = [\n",
    "    \"ffmpeg\", \"-y\", \"-i\", video_path,\n",
    "    \"-vf\", f\"subtitles={subtitle_path}:force_style='FontName=Noto Sans Telugu'\",\n",
    "    \"-c:a\", \"copy\",\n",
    "    output_path\n",
    "]\n",
    "\n",
    "subprocess.run(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f507c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "command = [\n",
    "                \"ffmpeg\", \"-i\", video_path,\n",
    "                \"-vf\", f\"subtitles={subtitle_path}\",\n",
    "                \"-c:a\", \"copy\",\n",
    "                output_path\n",
    "            ]\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from google.cloud import speech, translate_v2 as translate\n",
    "from google.cloud import storage\n",
    "import ffmpeg\n",
    "\n",
    "# Set credentials\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/home/csc/Downloads/nimixitsubtitling-05a073252e73.json\"\n",
    "\n",
    "class HindiToEnglishSRT:\n",
    "    def __init__(self, audio_path: str, srt_output_path: str = \"output.srt\", bucket_name: str = \"subtitling_gcs\"):\n",
    "        self.audio_path = audio_path\n",
    "        self.srt_output_path = srt_output_path\n",
    "        self.bucket_name = bucket_name\n",
    "        self.speech_client = speech.SpeechClient()\n",
    "        self.translate_client = translate.Client()\n",
    "        self.storage_client = storage.Client()\n",
    "\n",
    "    def preprocess_audio(self, output_path=\"cleaned.wav\"):\n",
    "        ffmpeg.input(self.audio_path).output(output_path, ar=16000, ac=1, format='wav').run(overwrite_output=True)\n",
    "        return output_path\n",
    "\n",
    "    def upload_to_gcs(self, file_path: str, blob_name: str) -> str:\n",
    "        bucket = self.storage_client.bucket(self.bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        blob.upload_from_filename(file_path)\n",
    "        gcs_uri = f\"gs://{self.bucket_name}/{blob_name}\"\n",
    "        print(f\"‚òÅÔ∏è Uploaded to GCS: {gcs_uri}\")\n",
    "        return gcs_uri\n",
    "\n",
    "    def to_srt_time(self, seconds):\n",
    "        td = datetime.timedelta(seconds=seconds)\n",
    "        return str(td).split('.')[0].zfill(8).replace(\".\", \",\") + f\",{int((td.total_seconds() - int(td.total_seconds())) * 1000):03}\"\n",
    "\n",
    "    def transcribe_and_translate(self, gcs_uri):\n",
    "        audio = speech.RecognitionAudio(uri=gcs_uri)\n",
    "        config = speech.RecognitionConfig(\n",
    "            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "            sample_rate_hertz=16000,\n",
    "            language_code=\"hi-IN\",\n",
    "            enable_automatic_punctuation=True,\n",
    "            enable_word_time_offsets=True\n",
    "        )\n",
    "\n",
    "        operation = self.speech_client.long_running_recognize(config=config, audio=audio)\n",
    "        print(\"‚è≥ Waiting for transcription...\")\n",
    "        response = operation.result(timeout=600)\n",
    "\n",
    "        segments = []\n",
    "        index = 1\n",
    "        for result in response.results:\n",
    "            alt = result.alternatives[0]\n",
    "            if not alt.words:\n",
    "                continue\n",
    "            start_time = alt.words[0].start_time.total_seconds()\n",
    "            end_time = alt.words[-1].end_time.total_seconds()\n",
    "            hindi_text = alt.transcript.strip()\n",
    "            english = self.translate_client.translate(hindi_text, target_language=\"en\")[\"translatedText\"]\n",
    "            segments.append({\n",
    "                \"index\": index,\n",
    "                \"start\": self.to_srt_time(start_time),\n",
    "                \"end\": self.to_srt_time(end_time),\n",
    "                \"text\": english\n",
    "            })\n",
    "            index += 1\n",
    "        return segments\n",
    "\n",
    "    def save_srt(self, segments):\n",
    "        with open(self.srt_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for seg in segments:\n",
    "                f.write(f\"{seg['index']}\\n\")\n",
    "                f.write(f\"{seg['start']} --> {seg['end']}\\n\")\n",
    "                f.write(f\"{seg['text']}\\n\\n\")\n",
    "\n",
    "    def run_pipeline(self):\n",
    "        print(\"üîß Preprocessing audio...\")\n",
    "        cleaned = self.preprocess_audio()\n",
    "        print(\"‚òÅÔ∏è Uploading to GCS...\")\n",
    "        gcs_uri = self.upload_to_gcs(cleaned, \"audio/cleaned.wav\")\n",
    "        print(\"üìù Transcribing and translating...\")\n",
    "        segments = self.transcribe_and_translate(gcs_uri)\n",
    "        print(\"üíæ Saving SRT...\")\n",
    "        self.save_srt(segments)\n",
    "        print(f\"‚úÖ Done! SRT saved at {self.srt_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba31b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = HindiToEnglishSRT(\n",
    "    audio_path=\"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/ahista_ahista/audio_files/ahista_ahista_part1_audio.mp3\",\n",
    "    srt_output_path=\"translated_subtitles.srt\"\n",
    ")\n",
    "converter.run_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deae58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ffmpeg\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from openai.types.audio import TranscriptionSegment\n",
    "\n",
    "class WhisperHindiToEnglishSRT:\n",
    "    def __init__(self, audio_path: str, output_srt: str = \"output.srt\", correct_grammar: bool = True):\n",
    "        self.audio_path = audio_path\n",
    "        self.output_srt = output_srt\n",
    "        self.correct_grammar = correct_grammar\n",
    "        self.wav_path = \"converted.wav\"\n",
    "        self.client = OpenAI(api_key=\"\")\n",
    "\n",
    "    def convert_to_wav(self):\n",
    "        print(\"üéß Converting audio to 16kHz mono WAV...\")\n",
    "        ffmpeg.input(self.audio_path).output(\n",
    "            self.wav_path, ar=16000, ac=1, format='wav'\n",
    "        ).run(overwrite_output=True)\n",
    "\n",
    "    def transcribe_with_whisper(self):\n",
    "        print(\"üìù Transcribing & translating with Whisper API...\")\n",
    "        with open(self.wav_path, \"rb\") as audio_file:\n",
    "            response = self.client.audio.translations.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=audio_file,\n",
    "                response_format=\"verbose_json\"\n",
    "            )\n",
    "        return response.segments\n",
    "\n",
    "    def correct_grammar_with_gpt(self, segments):\n",
    "        print(\"üî§ Correcting grammar using GPT-4...\")\n",
    "        corrected_segments = []\n",
    "        for seg in tqdm(segments):\n",
    "            res = self.client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a professional subtitle editor.\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"Correct grammar, punctuation and fluency: {seg.text}\"}\n",
    "                ]\n",
    "            )\n",
    "            corrected_text = res.choices[0].message.content.strip()\n",
    "            corrected_seg = {\n",
    "                \"text\": corrected_text,\n",
    "                \"start\": seg.start,\n",
    "                \"end\": seg.end\n",
    "            }\n",
    "            corrected_segments.append(corrected_seg)\n",
    "        return corrected_segments\n",
    "\n",
    "\n",
    "    def format_srt_timestamp(self, seconds: float) -> str:\n",
    "        td = datetime.timedelta(seconds=seconds)\n",
    "        total = str(td).split(\".\")[0]\n",
    "        milliseconds = int((td.total_seconds() - int(td.total_seconds())) * 1000)\n",
    "        return f\"{total},{milliseconds:03d}\"\n",
    "\n",
    "    def save_srt(self, segments):\n",
    "        print(f\"üíæ Saving SRT to {self.output_srt}...\")\n",
    "        with open(self.output_srt, \"w\", encoding=\"utf-8\") as f:\n",
    "            for i, seg in enumerate(segments):\n",
    "                start = self.format_srt_timestamp(seg.start)\n",
    "                end = self.format_srt_timestamp(seg.end)\n",
    "                f.write(f\"{i + 1}\\n{start} --> {end}\\n{seg.text.strip()}\\n\\n\")\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self.convert_to_wav()\n",
    "        segments = self.transcribe_with_whisper()\n",
    "        if self.correct_grammar:\n",
    "            segments = self.correct_grammar_with_gpt(segments)\n",
    "        self.save_srt(segments)\n",
    "        print(f\"‚úÖ Done! SRT saved at: {self.output_srt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680cb51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = WhisperHindiToEnglishSRT(\n",
    "    audio_path=\"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/ahista_ahista/audio_files/ahista_ahista_part1_audio.mp3\",  # ‚Üê change this\n",
    "    output_srt=\"translated_subtitles1.srt\",\n",
    "    correct_grammar=False\n",
    ")\n",
    "converter.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954f16e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def burn_subtitles_to_video(self, video_path: str, output_video_path: str):\n",
    "    print(f\"üé¨ Burning subtitles into video...\")\n",
    "    if not os.path.exists(self.output_srt):\n",
    "        raise FileNotFoundError(f\"SRT file not found: {self.output_srt}\")\n",
    "\n",
    "    if not os.path.exists(video_path):\n",
    "        raise FileNotFoundError(f\"Video file not found: {video_path}\")\n",
    "\n",
    "    # Use ffmpeg to burn subtitles\n",
    "    ffmpeg.input(video_path).output(\n",
    "        output_video_path,\n",
    "        vf=f\"subtitles={self.output_srt}\",\n",
    "        c=\"libx264\",\n",
    "        crf=23,\n",
    "        preset=\"medium\"\n",
    "    ).run(overwrite_output=True)\n",
    "\n",
    "    print(f\"‚úÖ Subtitled video saved at: {output_video_path}\")\n",
    "burn_subtitles_to_video(\n",
    "    video_path=\"/path/to/original_video.mp4\",\n",
    "    output_video_path=\"video_with_subtitles.mp4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917468c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the root project directory to sys.path\n",
    "project_root = os.path.abspath(\"..\")  # Adjust as needed\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from utils.config import get_settings\n",
    "get_settings().openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99def7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the root project directory to sys.path\n",
    "project_root = os.path.abspath(\"..\")  # Adjust as needed\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from models.translate import  TranslationUtils\n",
    "from utils.srt_parser import SRTTranslator\n",
    "translator = TranslationUtils() \n",
    "\n",
    "\n",
    "srt = SRTTranslator(translator)\n",
    "\n",
    "srt.translate_srt_file_batch_with_google_translate(\n",
    "    input_path=\"/home/csc/Downloads/ahista_ahista_part1_hin.srt\",\n",
    "    output_path=\"ahista_ahista_part1_telugu.srt\",\n",
    "    target_language=\"te\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f74b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/babloo_bachelor/split_files/babloo_bachelor_part2.mp4\"\n",
    "subtitle_path = \"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/babloo_bachelor/srt_files/Kannada/babloo_bachelor_part2__kn_SRTfile.ass\"\n",
    "output_path = \"babloo_bachelor_part2__kn_subtitled1.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "video_path = \"\"\n",
    "subtitle_path = \"\"\n",
    "output_path = \"\"\n",
    "\n",
    "command = [\n",
    "    \"ffmpeg\", \"-y\",\n",
    "    \"-i\", video_path,\n",
    "    \"-vf\", f\"subtitles='{subtitle_path}':fontsdir='/usr/share/fonts/truetype/noto':force_style='FontName=Noto Sans Kannada'\",\n",
    "    \"-c:a\", \"copy\",\n",
    "    output_path\n",
    "]\n",
    "\n",
    "subprocess.run(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4716a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = \"/home/csc/Documents/Multilingual-Transcriber\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from plugins.evalutions.evalution_new import TranslationEvaluator\n",
    "evaluator  = TranslationEvaluator()\n",
    "response = evaluator.generate_srt_pairs(src_dir=\"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/babloo_bachelor/srt_files/Base/\",\n",
    "                             tgt_dir=\"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/babloo_bachelor/srt_files/Kannada/\",\n",
    "                             src_suffix= \"__hi_SRTfile.srt\", \n",
    "                             tgt_suffix=\"__kn_SRTfile.srt\")\n",
    "\n",
    "evaluator.validate_batch_gemini(response, src_lang=\"Hindi\", tgt_lang=\"Kannada\", output_dir=\"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/babloo_bachelor/evaluation/Kannada/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176440ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = \"/home/csc/Documents/Multilingual-Transcriber\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from plugins.evalutions.evalution import rename_srt_files_with_language\n",
    "rename_srt_files_with_language(directory=\"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/babloo_bachelor/srt_files/Base/\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb81a369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "\n",
    "class TranslationEvaluator:\n",
    "    def __init__(self, api_key: str):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-1.5-pro\")  # ‚úÖ FIX\n",
    "\n",
    "    def evaluate_translation_gemini(self, \n",
    "                                    text_src: str,\n",
    "                                    text_tgt: str,\n",
    "                                    src_lang: str = \" \",\n",
    "                                    tgt_lang: str = \" \",\n",
    "                                    retries: int = 3) -> float:\n",
    "        if not text_src.strip() or not text_tgt.strip():\n",
    "            return 0.0\n",
    "\n",
    "        system_msg = (\n",
    "            \"You are a professional evaluator of translation quality.\\n\"\n",
    "            \"Judge how well Text-TGT conveys the meaning of Text-SRC.\\n\"\n",
    "            \"Ignore minor typos, small transcription errors, or differences in phrasing, \"\n",
    "            \"as long as the meaning and spoken intent are preserved.\\n\"\n",
    "            \"Phonetic or sounding-similar translations are acceptable.\\n\"\n",
    "            \"Only respond with JSON: {\\\"score\\\": float between 0 and 1}.\\n\"\n",
    "        )\n",
    "\n",
    "        user_msg = f\"Text-SRC ({src_lang}): {text_src.strip()}\\n\" \\\n",
    "                   f\"Text-TGT ({tgt_lang}): {text_tgt.strip()}\"\n",
    "\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                response = self.model.generate_content(\n",
    "                    contents=[{\"role\": \"user\", \"parts\": [{\"text\": system_msg + \"\\n\\n\" + user_msg}]}]\n",
    "                )\n",
    "                content = response.text.strip()\n",
    "\n",
    "                if content.startswith(\"```\"):\n",
    "                    content = content.strip(\"`\").split(\"```\")[1] if \"```\" in content[3:] else content.strip(\"`\")\n",
    "\n",
    "                score = float(json.loads(content)[\"score\"])\n",
    "                return score\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[attempt {attempt + 1}] Gemini error: {e}\")\n",
    "                time.sleep(1)\n",
    "\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "379ff3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = \"/home/csc/Documents/Multilingual-Transcriber\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "from plugins.evalutions.evalution_new import TranslationEvaluator\n",
    "evaluator  = TranslationEvaluator()\n",
    "\n",
    "\n",
    "evaluator.validate_pair_gemini(src_file =\"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/babloo_bachelor/srt_files/Base/babloo_bachelor_part2__hi_SRTfile.srt\",\n",
    "                               tgt_file=\"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/babloo_bachelor/srt_files/Kannada/babloo_bachelor_part2__kn_SRTfile.srt\", \n",
    "                               out_csv=\"/home/csc/Documents/Multilingual-Transcriber/shared_data/movieslist/babloo_bachelor/evaluation/Kannada/test.csv\",\n",
    "                      src_lang=\"Hindi\", tgt_lang=\"Kannada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6570ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai.types import HttpOptions\n",
    "\n",
    "client = genai.Client(http_options=HttpOptions(api_version=\"v1\"), api_key=\"\")\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"How does AI work?\",\n",
    ")\n",
    "print(response.text)\n",
    "# Example response:\n",
    "# Okay, let's break down how AI works. It's a broad field, so I'll focus on the ...\n",
    "#\n",
    "# Here's a simplified overview:\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5be100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "import moviepy.editor as mp\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import numpy as np\n",
    "import threading\n",
    "import os\n",
    "import time\n",
    "\n",
    "# --- Global Settings ---\n",
    "SAMPLERATE = 44100  # Samples per second for audio recording\n",
    "TEMP_AUDIO_FILENAME = \"temp_dubbed_audio.wav\"\n",
    "\n",
    "class DubbingApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Simple Dubber POC\")\n",
    "        self.root.geometry(\"400x250\")\n",
    "\n",
    "        self.video_path = None\n",
    "        self.recording_thread = None\n",
    "        self.is_recording = False\n",
    "        self.recorded_frames = []\n",
    "\n",
    "        # --- UI Elements ---\n",
    "        self.label = tk.Label(root, text=\"1. Select a video file to dub\", font=(\"Arial\", 12))\n",
    "        self.label.pack(pady=10)\n",
    "\n",
    "        self.btn_load = tk.Button(root, text=\"Load Video\", command=self.load_video)\n",
    "        self.btn_load.pack(pady=5)\n",
    "\n",
    "        self.status_label = tk.Label(root, text=\"No video loaded.\", wraplength=380)\n",
    "        self.status_label.pack(pady=10)\n",
    "\n",
    "        self.btn_record = tk.Button(root, text=\"Start Dubbing\", state=tk.DISABLED, command=self.start_dubbing_process)\n",
    "        self.btn_record.pack(pady=10)\n",
    "\n",
    "        self.btn_export = tk.Button(root, text=\"Export Video\", state=tk.DISABLED, command=self.export_video)\n",
    "        self.btn_export.pack(pady=10)\n",
    "\n",
    "    def load_video(self):\n",
    "        \"\"\"Opens a file dialog to select a video file.\"\"\"\n",
    "        path = filedialog.askopenfilename(\n",
    "            filetypes=[(\"Video Files\", \"*.mp4 *.mkv *.avi\"), (\"All files\", \"*.*\")]\n",
    "        )\n",
    "        if path:\n",
    "            self.video_path = path\n",
    "            self.status_label.config(text=f\"Loaded: {os.path.basename(self.video_path)}\")\n",
    "            self.btn_record.config(state=tk.NORMAL)\n",
    "            self.btn_export.config(state=tk.DISABLED) # Disable export until a recording is made\n",
    "            print(f\"Video loaded: {self.video_path}\")\n",
    "            # Clean up old recordings if a new video is loaded\n",
    "            if os.path.exists(TEMP_AUDIO_FILENAME):\n",
    "                os.remove(TEMP_AUDIO_FILENAME)\n",
    "\n",
    "\n",
    "    def start_dubbing_process(self):\n",
    "        \"\"\"Starts the video playback and audio recording in separate threads.\"\"\"\n",
    "        if not self.video_path:\n",
    "            messagebox.showerror(\"Error\", \"No video file loaded.\")\n",
    "            return\n",
    "\n",
    "        self.btn_load.config(state=tk.DISABLED)\n",
    "        self.btn_record.config(state=tk.DISABLED, text=\"Recording...\")\n",
    "        self.status_label.config(text=\"Recording... Watch the video and speak!\")\n",
    "\n",
    "        # Thread for playing video\n",
    "        video_thread = threading.Thread(target=self.play_video)\n",
    "        \n",
    "        # Thread for recording audio\n",
    "        self.recording_thread = threading.Thread(target=self.record_audio)\n",
    "\n",
    "        video_thread.start()\n",
    "        self.recording_thread.start()\n",
    "        \n",
    "        # Check periodically if threads are done\n",
    "        self.root.after(100, self.check_dubbing_finished)\n",
    "\n",
    "    def play_video(self):\n",
    "        \"\"\"Plays the video clip using MoviePy's preview.\"\"\"\n",
    "        print(\"Starting video playback...\")\n",
    "        try:\n",
    "            with mp.VideoFileClip(self.video_path) as clip:\n",
    "                # preview will block until the video is finished or closed\n",
    "                clip.preview()\n",
    "        except Exception as e:\n",
    "            print(f\"Error playing video: {e}\")\n",
    "        print(\"Video playback finished.\")\n",
    "\n",
    "    def record_audio(self):\n",
    "        \"\"\"Records audio from the microphone for the duration of the video.\"\"\"\n",
    "        print(\"Starting audio recording...\")\n",
    "        self.is_recording = True\n",
    "        self.recorded_frames = []\n",
    "\n",
    "        try:\n",
    "            with mp.VideoFileClip(self.video_path) as clip:\n",
    "                duration = clip.duration\n",
    "\n",
    "            # Define a callback function for the audio stream\n",
    "            def callback(indata, frames, time, status):\n",
    "                if status:\n",
    "                    print(status)\n",
    "                self.recorded_frames.append(indata.copy())\n",
    "\n",
    "            # Start recording\n",
    "            with sd.InputStream(samplerate=SAMPLERATE, channels=1, callback=callback):\n",
    "                # We can't just sleep for the duration, because the video player might be closed early.\n",
    "                # Instead, we rely on the main thread to stop us.\n",
    "                # A more robust solution would use inter-thread communication.\n",
    "                # For this POC, we just let it record until the app state changes.\n",
    "                while self.is_recording:\n",
    "                    sd.sleep(100) # Sleep in short intervals\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during audio recording: {e}\")\n",
    "        \n",
    "        print(\"Audio recording stopped.\")\n",
    "        # Once stopped, save the file\n",
    "        if self.recorded_frames:\n",
    "            recording = np.concatenate(self.recorded_frames, axis=0)\n",
    "            write(TEMP_AUDIO_FILENAME, SAMPLERATE, recording)\n",
    "            print(f\"Audio saved to {TEMP_AUDIO_FILENAME}\")\n",
    "            self.root.after(0, lambda: self.btn_export.config(state=tk.NORMAL))\n",
    "\n",
    "\n",
    "    def check_dubbing_finished(self):\n",
    "        \"\"\"Checks if the recording process is complete and updates the UI.\"\"\"\n",
    "        # A simple way to detect finish: the preview window is gone.\n",
    "        # A more robust check would be needed for a real app.\n",
    "        # We assume the user closes the video window to stop recording.\n",
    "        \n",
    "        # Find the preview window\n",
    "        preview_active = False\n",
    "        for w in tk.Tk().winfo_children(): # A bit of a hack to find the SDL window\n",
    "            if \"pygame\" in str(w):\n",
    "                preview_active = True\n",
    "                break\n",
    "        \n",
    "        # A better check: is the recording thread alive?\n",
    "        if self.recording_thread and self.recording_thread.is_alive():\n",
    "            self.root.after(100, self.check_dubbing_finished)\n",
    "        else:\n",
    "            self.is_recording = False # Signal recording thread to stop\n",
    "            self.btn_load.config(state=tk.NORMAL)\n",
    "            self.btn_record.config(state=tk.NORMAL, text=\"Start Dubbing\")\n",
    "            self.status_label.config(text=\"Recording finished. Ready to export.\")\n",
    "\n",
    "\n",
    "    def export_video(self):\n",
    "        \"\"\"Merges the recorded audio with the video and saves it.\"\"\"\n",
    "        if not self.video_path or not os.path.exists(TEMP_AUDIO_FILENAME):\n",
    "            messagebox.showerror(\"Error\", \"No recorded audio found to export.\")\n",
    "            return\n",
    "\n",
    "        save_path = filedialog.asksaveasfilename(\n",
    "            defaultextension=\".mp4\",\n",
    "            filetypes=[(\"MP4 Video\", \"*.mp4\")]\n",
    "        )\n",
    "        if not save_path:\n",
    "            return\n",
    "\n",
    "        self.status_label.config(text=\"Exporting... This may take a while.\")\n",
    "        self.root.update() # Force UI update\n",
    "\n",
    "        try:\n",
    "            print(\"Loading original video clip...\")\n",
    "            video_clip = mp.VideoFileClip(self.video_path)\n",
    "            \n",
    "            print(\"Loading dubbed audio clip...\")\n",
    "            audio_clip = mp.AudioFileClip(TEMP_AUDIO_FILENAME)\n",
    "            \n",
    "            # If audio is longer than video, trim it\n",
    "            if audio_clip.duration > video_clip.duration:\n",
    "                audio_clip = audio_clip.subclip(0, video_clip.duration)\n",
    "\n",
    "            print(\"Replacing audio and writing to file...\")\n",
    "            final_clip = video_clip.set_audio(audio_clip)\n",
    "            \n",
    "            # Use a good codec, add threads for speed\n",
    "            final_clip.write_videofile(save_path, codec='libx264', audio_codec='aac', threads=4)\n",
    "\n",
    "            messagebox.showinfo(\"Success\", f\"Video successfully exported to {save_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Export Error\", f\"An error occurred: {e}\")\n",
    "        finally:\n",
    "            # Clean up\n",
    "            self.status_label.config(text=\"Export finished. Load a new video or re-dub.\")\n",
    "            video_clip.close()\n",
    "            audio_clip.close()\n",
    "            if os.path.exists(TEMP_AUDIO_FILENAME):\n",
    "                os.remove(TEMP_AUDIO_FILENAME)\n",
    "            self.btn_export.config(state=tk.DISABLED)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = DubbingApp(root)\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transcriber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
